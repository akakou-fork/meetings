# March 29, 2024

## Logistics

12-1 PM EDT / 9-10AM PDT / 4-5PM GMT

## Agenda

* Shared Storage and Anti-Fraud (30 mins)
* DiStefano: Tech Deep Dive (30 mins)

## Resources

* [Minutes](https://docs.google.com/document/d/1pYGrrb3J3rHSNWnCcyE1IlbbiDzKXwU0QwNY4TwYC28/edit?usp=sharing)
* [Chair Slides](https://docs.google.com/presentation/d/1jxUT_BK_c0aco-aWpwpyBBS0j1GXwMs84Pq-OT4sjAM/edit?usp=sharing&resourcekey=0-svVepjJM0kL735tpDWIgCg)
* [Shared Storage Slides](https://docs.google.com/presentation/d/1XXgpwQLmfh87oQ3q5I3mzocUjLdjtTQMqLMLGb2nIMY/edit?usp=sharing)

## Minutes
Steven:

Only topic today is shared storage in AFCG. \
 \
Jonathan Feinberg: Shared Storage

Jonathan: Manages a group at Google including steven and others here on Antifraud in Privacy Sandbox. This presentation describes what shared storage is, and how it fits into other similar technologies.  People in this room may not be super familiar with Shared Storage. Will then show a demo of recreating Cookie Age using Shared Storage. At the end there will be time for questions. Goal is to consider whether shared storage might be useful for an antifraud context, with the theme being on-device computation with limited entropy.

3PCD address more than just cookies. For example, storage is also partitioned (local storage, indexdb, etc).

It used to be the case that if example.com is embedded in a.com, they can set a cookie. And later when they are embedded in b.com, they can read that cookie. That is now going away.

In Shared storage, writing has no extra gates. But reading is more complicated. Reading requires choosing an output gate. An example output gate is the Private Aggregation API. Here, values are stored into shared storage by bucket, and can only be read by an aggregation service running in a TEE, where the values are aggregated by key in a predefined way w/ differential privacy parameters, and output from the TEE. For those who don’t know the TEE is an attestable, verifiable service that receives it’s keys from a coordinator service and can be externally audited.

The other output gate is simpler. The browser is given a list of URLs. A computation (SelectURL) returns an index into that list of URLs, and the URL can be accessed and rendered from within a &lt;fencedframe>. Common use cases (see slides): Creative rotation, A/B testing, UX experiences, Anti-abuse mitigations, Unique reach reporting.

In our documentation, we refer to antiabuse mitigations. There is no link for that because it simply isn’t being done yet. The point of all of this is to get you to voice your opinion on what sort of output gate would be suitable/useful for anti-abuse. Some of you may remember a proposal for a cookie age signal derived from shared storage by Philipp.

Demo time. Jonathan demo’s Philipp’s cookie age demo. First, the features need to be enabled that allow shared storage, and the test URLs must be enrolled in shared storage. This demo page stands for a publisher (e.g. blog). Inside the iframe, lets imagine there is an AAF provider. This iframe sets a cookie value if it isn’t already present. This iframe also shows what is contained within the shared storage, by rendering it from within a fencedframe (e.g. javascript cannot read this). To prove that this is cross-site, jonathan navigates to a completely different domain, showing the cookie is still mature. We can also see there is a button to reset the cookie to fresh.

That is the demo, now we’ll look at the code driving this.

Brian May: So you’re doing this in a fenced frame. This is to communicate with the person running the browser? \
 \
Jonathan: This is just me demonstrating that the service end (the antiabuse end) is seeing the right thing in the fenced frame. \
 \
Brian may: In the context of a fenced frame, you know if something is true or false. What do you do with that information? \
 \
Jonathan: One way I imagine this would work, is you are detecting that something is happening (tracking it) and you are taking action post-hoc. One way or another the publisher is communicating with the AAF provider, and once the shared storage dance is done, the AAF provider can attempt to communicate that. BTW, these are precisely the relevant questions for this discussion.

Eric: On the fencedframe topic, right now you can render this url in a normal iframe, at least until 2026. Considering the longer term uses, there is an opportunity for AAF users to use Private Aggregation API to understand distributions. I understand that fencedframes may be difficult for some AAF implementers, and we’d like to hear more about this use case.

Jonathan: I was aware of that (not that it would be available for that long), but I wanted to implement something in a more restrictive situation. \
 \
Now on to the source code.

The code has an ignoreIfPresent option, which allows one to only set the value if it isn’t already present, meaning the user code can always just attempt to set the value to a fresh cookieage.

Here is the worklet, this runs in a sandbox that can’t do anything (network etc) except return a small (in bit size) integer. Here, we see that the code can call one of 3 different URLs, one corresponding to each cookie age bucket. This worklet gets registered by calling “sharedStorage.worklet.addModule(foo.js)”.

Brian May: Is there a limit to the number of times you can call the shared storage api? \
 \
Jonathan: There is a per-page limit to how many times you can invoke the worklet.

Eric: 3 bits for the 8 possible values, and 15 bits total per week. This is in the spec, and set by the browser. We need to double check the spec. (Adding here:  https://github.com/WICG/shared-storage?tab=readme-ov-file#budget-details) 

Steven: Bhanu says it is 12 bits per page load per day (and is correct).

Back to the code: \
Shared storage has one function per output gate for reading things. SelectURL is the one I’m using. You tell it what worklet to use and pass along a list of URLs. On the server it’s expecting to be called with one of those URLs, and that is how it derives meaning. Keep-alive is just for the purpose of the demo. The result of that computation gets set as the config property of the fenced frame.

The entire demo is this handleAge function, plus the other two slides presented.

Jonathan: I will share these slides, including links to the demo. Feel free to dig in. Other resources are linked here as well. I also shared a screen shot to the purpose built cookie age API, which may be of interest.

Questions? Discussion? Thank you.

Steven: This SelectURL thing is sort of complicated, and may be overkill for AAF use cases when you just want to send a ping to the server.  \
 \
Jonathan: Not going to comment on what future work Google is going to do, but what is needed is a better design for the purpose. \
 \
Bhanu: I understand the per-site, per-load entropy limits, we want to protect users. If the API becomes popular, and we have a lot of adtechs using this api, they will run into the overall page-level entropy limits without necessarily getting the data they want (partial computation?)

Eric: Right now we don’t have a plan to address this. If this API is useful to AAF implementers, we are interested in addressing these issues. From my perspective, AAF is one of many purposes here.

Sam: This is an issue for other work that we’re doing, like the total page limit for redemption in PST. These bandwidth limits are necessary, but it causes issues with other websites being included. Want to get consensus in the community.

Brian: It’s useful when you get a response. From my experience with the data minimization efforts, you don’t get a response when you’ve exhausted your queries. You don’t know if the data is unavailable, or if the limit was exhausted or the query failed for another reason. \
 \
Jonathan: Would it be helpful to get a status code back to the API? \
 \
Brian: That raises the concern of people using the status codes to exfiltrate more entropy out of the api, so you blackhole it.

Jonathan: What is the hypothetical calculation on a single page load that would exhaust the budget. \
 \
Sam: A site has multiple antifraud vendors embedded on the page. The page load budget could be consumed by the fastest antifraud vendor.

Bhanu: If there are 4 adtechs on a page competing with eachother, everything is good. Once you add a 5th on the page, 20% of loads will fail.

Brian: Folks in AdTech will try to take advantage of any API surface available and likely will apply this API to novel use-cases it was not anticipated to be used for.

 \
Jonathan: We call that Hyrums law at google. Any api surface that exists, documented or not, becomes the de-facto api. \
 \
Scott: I’m hearing 2 areas people want to explore: budgets and \_\_\_. Steven your question was more about API usability. Are people interested in a forum change? Is that needed to make this discussion useful? \
 \
Brian: Wondering why it returns a URL and not an index. \
 \
Jonathan: My guess is that originally all you could do was get the worklet to configure the fenced frame.

Eric: Yes the original use case for URL only was Ads focused, like creative rotation. These are things that are potentially improvable, and it is important to think through on-device processing with limited entropy leakage to make this more useful for this group.

Sam: The big thing that I noticed is that the client can just lie about its cookie age, so something verifiable would be helpful. Could be through shared storage or the workelt.

Brian: Had the same thought about manipulation. To the general question as to whether this is useful, I would say yes. Some information is better than none, we will just have to be mindful of limitations. \
 \
Steven: How often is a malicious client in the threat model? \
Brian: If there is uneven support across browsers, and we don’t have a lot of information about when this call is made and why it failed, it’s hard to know. If browsers just don’t support a given trustworthiness check, that is another confounding factor. \
 \
Scott: This is replacing 3P cookies, and those don’t necessarily have that trust factor either. We should be careful of introducing new methods of trust and focus on those that already exist (signing data on the server). \
 \
Brian: With the shrinking of available signals, the signals we do have will need to be more trustworthy. \
 \
Sam: This falls into some discussions in the broader browser community. If you were to make this verifiable in some way, then it would fall into the category of a cross-site limited bandwidth channel with verifiability. Privacy pass relies on a token economy, where here there still has to be some rate limiting inherent in the api. \
 \
Jonathan: While we’re gathering comments and questions, are there any other usecases or shapes that come immediately to mind.  \
 \
Sam: A website could ask you to show your government Id and then pass that to the server \
 \
Brain; When I was involved in antifraud, I would use any signal that I could. One interesting use of this would be, is this a browser I’ve seen before.

Jonathan: General theme in privacy sandbox: making exceptions through various mechanisms for people who get to see more data. I think we’re hoping to eliminate exceptions and increase the utility of purpose-build stuff.

Brain: Concerns about the specificity of the query that can be made. Can I stamp everyone who visits on my website who visit in a very specific time frame, and query that after the fact? \
 \
Jonathan: I think in principle, yes. \
 \
Sam: YOu can do that with the existing APIs of Private State Tokens. This is actually worse, where you can use contextual information from the 1P context to choose what bits you get out.  \
 \
Brian: That leads me to think that there needs  to be a canned set of questions that can be asked vs a general purpose capability.  \


Brian: Is there a place in github that we are pursuing this? \
 \
Steven: Open an issue in the AFCG proposals repo. Jonathan can open the issue and other folks can respond there.
