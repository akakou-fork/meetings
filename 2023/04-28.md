# April 28, 2023

## Logistics

12-1 PM EDT / 9-10AM PDT / 4-5PM GMT

## Agenda

* Web Environment Integrity (60 mins)

## Resources

* [Minutes](https://docs.google.com/document/d/17r8MhwyM5VhLRogPdkt2GSgSSgF_Cl62cHSCwVdMnqg/edit?usp=sharing)
* [Chair Slides](https://docs.google.com/presentation/d/1X4tt_OLTAVeZjMs32Bir-vVPvdsasvJq4XyTJr8UvFE/edit?usp=sharing)
* [Web Environment Integrity Explainer](https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md)
* [Web Environment Integrity Slides](https://docs.google.com/presentation/d/1c2-gv9S4OubZ3R5mI_uhSF_FbBxJXmfhBVEbej5BCYc/edit?usp=sharing&resourcekey=0-SjaQ22SUKgYNuHEp_XGlAQ)

## Minutes
Steven: Reach out to chairs if you would like to be a co-chair for AFCG.
Ben Wiser presenting [Web Environment Integrity AP](https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md)I, link to [slides](https://docs.google.com/presentation/d/1c2-gv9S4OubZ3R5mI_uhSF_FbBxJXmfhBVEbej5BCYc/edit?resourcekey=0-SjaQ22SUKgYNuHEp_XGlAQ#slide=id.p). 
Web Environment Integrity API: belief is that if web sites can get a bit more information about the environment that they’re running in, there might not need to be quite so much tracking
Discussion:
Philipp Pfeiffenberger: At this point, the explainer is still focusing on goals and requirements but many of the details are hand-wavey. Would like to focus on the problem space before digging into the solutions.
Brian May: Working on this in a different WG. Wondering what is the depth of the web client represented in the diagram? 
Ben Wiser: A bit of a middle ground to make the diagram simple. Some OS level API you could pull from. Browser makes a trusted OS call that it has no control over. We did not wante to prescribe that as an explicit requirement. But we expect this to be an OS thing. 
Tommy Pauly: One of the things I noticed is that the explainer doesn’t use privacy pass. It seems like it fits into the privacy pass architecture, maybe as a new token type. I’d encourage us to use the architecture at least, rather than creating a new mechanism. If we want different visibility of metadata, maybe we try to extend Privacy Pass.
Philipp: I’ve had some conversations with the Privacy Pass folks - and it seems like there isn’t appetite to adopt debuggability within the Privacy Pass framework. But if that isn’t true,  we ought to dig in on that. Fast local attestations might be added to PP as well. Need to brainstorm around that. 
 \Tommy Pauly: Would like ‘shape of the container’ to at least follow privacy pass. Debuggability could be implemented via public metadata. Would be useful to have the whole community analyze the whole solution - because it’d be great to find a solution that isn’t suboptimal for privacy in either way. \

Philipp Pfeiffenberger: Asking about the best forum in which to follow up on this discussion.
Matt Jones: Overall shape is useful. Youtube has a lot of attackers in comments and watch abuse. One mechanism is running youtube on a web page on a phone. Getting a signal from the phone might be useful to detect the abuse. Getting device attestation data from a web page would be really useful.
Kevin Gibbons: Agreed this would be useful at F5 - would be extremely useful for our use case. You had a point about things that should count as tampered v. un-tampered and mentioned extensions. Agree in principle that extensions shouldn’t knock against users, but there are malicious extensions so would like to have a more nuanced perspective.
Philipp Pfeiffenberger: when we started looking at this, we found lots of angles of integrity that were important to folks. Different complexities to each of these. But the place we want to start is “is there a physical device there” In that model, the browser is a pass-through. And if we get some utility out of that, we can try other applications that balance the user agency concerns, viability of multiple browser, etc.
Kevin Gibbons: That sounds like a reasonable place to start - and would like to talk more about the rate limiting story.
Michael Ficarra - iterating on attested properties: In explainer there are some certain properties/ideas we might attest. I do not think this is the appropriate time to discuss these, however, I would like to give feedback on those. I can create issues. 
Ben: Issues are good.
Nick Doty - holdouts, and limited debuggability compared to current systems. This is a useful discussion, I’ve had similar reactions that is that this seems similar to privacy pass. Want to talk about holdbacks – this seems promising for getting at some aggregate level of risk while avoiding being a gating factor. Interest in details, but seems promising. On debuggability, seems like that’s the most important conversation for us to have. On the Privacy Pass side, the goal was that the Attester or the reliant party didn’t have a constant connection; if reliant parties are colluding with the attesters, that’d be really bad for our privacy goals. If there is a mechanism to do this sparingly, that may make sense. But if we put metadata into every attestation, we would be setting up a system where collusion is possible.
Philipp Pfeiffenberger: What is the utility loss? Threat of attestation collaboration is within the threat model. We are iterating on how to do these.
Nick Doty: Not so concerned about the percentage, but the fact that there’s a mechanism such that we have some confidence that this is throttled (and provide that confidence to users)
Philipp Pfeiffenberger: That is aligned with our goals.
Borbala Benko -- trade-offs: Comments on the privacy pass relationship. There are no concrete implementation details in the explainer yet. What is in the explainer is defining trade-offs. One is sustained anti-abuse value. How to find solutions that has anti-abuse value over time. Second part is usability. For a solution that protects medium QPS traffic, how to introduce cheaper attestations. Not sure whether this is compatible with privacy pass. Third part is on inclusivity. We do not want  to introduce a scheme that favors devices that cost more. There is probably no easy definition of what is trusted and what is not. How can we introduce flexibility while remaining inclusive & secure? This is where the discussion around semantics becomes important.
Michael Ficarra - difficulty maintaining info about which environments may be trustable; I briefly brought this up on the original proposal on our issue tracker, but the work of maintaining info about what platforms may be trusted is significant. Requires anyone doing verification to maintain lists of compromised devices, follow compromises in OSes. For someone like F5 who would benefit from this greatly, it’d be worth doing that. But there are a very small number of parties who would be willing to be able to do verifications. Is that an issue? Are there ideas for how smaller entities could take advantage of this?
Philipp Pfeiffenberger: No good solutions here. How good is a startup vs a large tech company? There is a reconcilable balance between allowing startups to provide some attestation signal and the security of those signals. We would like it to be financially achievable for small producers to build this into their products. We will share some of our ideas down the line and there is room for innovation
Brian May: when I’ve looked at this, I’ve looked at separating out the active attesting from signaling what has been attested to. That’d allow each level of the client to provide attestations up the chain, accompanied by information that would allow each to evaluate whether the attestation is true. Would allow a site to say “I can trust this app, but I don't care about the OS.” For ads use cases, as a publisher of a website, I don’t really care about the device being valid, but someone paying for an impression may want to know that so they can adjust the bid. If we allow lots of ppl to do attestation, they could do it on a sampling basis, and we may have enough confidence that there are enough ppl validating attestations and we could have enough collective confidence in the resource chain.
Philipp: Not all organizations will be attacked with the same frequency. Some sort of comprehensive evaluation would help. Some crime groups might specialize in a certain platform. Specific attesters might solve this problem. 
Steven Valdez - privacypass: Without knowing the technical requirements, it’s not totally clear how much support you’d need in PP. There is a proposal from Scott Hendrickson to have increased metadata for debuggability, and it may be helpful to sync to align on how to take forward
Betul Durak - I’m here form Microsoft research. Not clear on the different types of drafts: privacy pass, rate limiting, etc. There are a lot of differences of design and it’s not clear how interoperable and iterable they all are. Are we taking the discussion of all of these schemes to other forums, and who is responsible for standardizing all of them.
Steven: The intent in the AFCG is to work on the web-exposed parts of this problem. The crypto primitives would probably be done in the IETF to establish; but there may be an interim time where we need to discuss here and then bring to IETF or another body.
Betul: One solution will not fit all.  \ \Philipp: How to find overlap with PP - would like to sharpen this into a detailed proposal, and then see how much carries over to privacy pass. We will discuss it again after we flush out the spec.
Michael Ficarra - feasibility of hold-backs long term:  \Unconvinced by holdbacks and the solution they are trying to solve. If we do this it will reduce the usefulness in the automation and antifraud use case. Will only be able to reduce the number of environments that we treat with suspicion. I don’t feel that this is a new problem. There are already cases where old browsers are excluded from accessing services based on feature support such as TLS vers, etc.
Borbala: I don’t think we’re completely thinking through all of the issues with holdouts. At some point it’s possible the holdout groups have larger amounts of bots and then websites may treat as more suspicious. We need to think more deeply about the problem we’re trying to solve. It’s not clear to me where it leads in the end.
Tommy: Wanted to comment on the discussion earlier on smaller players. Super important to make sure we have an open market here and referring to the Privacy Pass terms here – that was one of the reasons we had a split attester/issuer model. What I’m seeing here is more of the unified model, but splitting may be helpful. I get concerned if the individual websites need to maintain lists about what they trust or not. Even if we intend to be open, it may ossify. A split model allows just the website to trust the issuer (and then the issuer trusts the attester). Would mean that the websites can’t limit access.
Philipp: We’ll come back with more detailed considerations - definitely something we’re thinking about.
Sergey: Utility difference is PP issues tokens that are blinded. In current proposal attestation is bound to the request user is making. 
Betul: Browser is untrusted. 
Sergey: Not enough time left to talk about this in detail.
Brian: Interested in separating some of these concerns - thinking of a protocol where there’s a defined way to validate the attestation. You could use Privacy Pass or whatever mechanism, but communicate these things in such a way over a standard protocol.
Philipp: Uplevel requirement. Embedded third parties need access to all of the information? File as an issue and we can follow up.